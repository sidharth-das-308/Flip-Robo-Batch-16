{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "    \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/  \n",
    "You need to find following details:   \n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required library\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostviewed_videos():\n",
    "    \"\"\"Creating function that searches details of most viewed videos on YouTube from Wikipedia\"\"\"\n",
    "    \n",
    "    template = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'#URL template for accessing the website\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path =\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver\n",
    "    driver.get(template) #Opening with the URL template\n",
    "    driver.maximize_window() #Maximize the Window\n",
    "    \n",
    "    details = [] #Declaring a Dummy list for storing the details\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//table [@class = 'wikitable sortable jquery-tablesorter']/tbody/tr/td\"):\n",
    "        details.append(i.text)\n",
    "        \n",
    "    driver.close() #Exiting the driver post scraping the information\n",
    "    \n",
    "    details= details[:180] #Removing the unwanted details from the list\n",
    "    \n",
    "    Rank = [] #list for storing the Rank of the vedio.\n",
    "    Name = [] #list for storing the Name of the vedio.\n",
    "    Artist = [] #list for storing the Artist of the vedio.\n",
    "    Views = [] #list for storing the Views of the vedio.\n",
    "    Upload_date = [] #list for storing the Uploaded date of the vedio.\n",
    "\n",
    "    z= 0\n",
    "    while z < len(details): # Splitting the collected table details and storing the details appropriately\n",
    "        Rank.append(details[z])\n",
    "        z+=1\n",
    "        Name.append(details[z])\n",
    "        z+=1\n",
    "        Artist.append(details[z])\n",
    "        z+=1\n",
    "        Views.append(details[z])\n",
    "        z+=1\n",
    "        Upload_date.append(details[z])\n",
    "        z+=2\n",
    "    \n",
    "    #Creating the DataFrame from all collected data\n",
    "    table = pd.DataFrame({\"Rank\" : Rank,\n",
    "                          \"Name\" : Name, \n",
    "                          \"Artist\" : Artist,\n",
    "                          \"Upload date\" : Upload_date,\n",
    "                          \"Views\" : Views\n",
    "    })        \n",
    "    \n",
    "    \n",
    "    return table#returns the DataFrame with collected details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Bath Song\"[31]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[33]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[38]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sorry\"[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Wheels on the Bus\"[43]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Dark Horse\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Shake It Off\"[46]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[53]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Axel F\"[54]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Hello\"[55]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"[22]   \n",
       "1    2.                                  \"Despacito\"[24]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[25]   \n",
       "3    4.                               \"Shape of You\"[26]   \n",
       "4    5.                              \"See You Again\"[27]   \n",
       "5    6.   \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "6    7.                                  \"Bath Song\"[31]   \n",
       "7    8.  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "8    9.                                \"Uptown Funk\"[33]   \n",
       "9   10.                              \"Gangnam Style\"[34]   \n",
       "10  11.                \"Phonics Song with Two Words\"[36]   \n",
       "11  12.                                      \"Sugar\"[37]   \n",
       "12  13.                             \"Dame Tu Cosita\"[38]   \n",
       "13  14.                                      \"Sorry\"[39]   \n",
       "14  15.                                       \"Roar\"[40]   \n",
       "15  16.                             \"Counting Stars\"[41]   \n",
       "16  17.                          \"Thinking Out Loud\"[42]   \n",
       "17  18.                          \"Wheels on the Bus\"[43]   \n",
       "18  19.                                 \"Dark Horse\"[44]   \n",
       "19  20.                                      \"Faded\"[45]   \n",
       "20  21.                               \"Shake It Off\"[46]   \n",
       "21  22.                             \"Girls Like You\"[47]   \n",
       "22  23.                                    \"Lean On\"[48]   \n",
       "23  24.                                   \"Bailando\"[49]   \n",
       "24  25.                                 \"Let Her Go\"[50]   \n",
       "25  26.                                   \"Mi Gente\"[51]   \n",
       "26  27.                                    \"Perfect\"[52]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[53]   \n",
       "28  29.                                     \"Axel F\"[54]   \n",
       "29  30.                                      \"Hello\"[55]   \n",
       "\n",
       "                            Artist        Upload date Views  \n",
       "0   Pinkfong Kids' Songs & Stories      June 17, 2016  8.95  \n",
       "1                       Luis Fonsi   January 12, 2017  7.44  \n",
       "2                      LooLoo Kids    October 8, 2016  5.54  \n",
       "3                       Ed Sheeran   January 30, 2017  5.38  \n",
       "4                      Wiz Khalifa      April 6, 2015  5.17  \n",
       "5                       Get Movies   January 31, 2012  4.44  \n",
       "6       Cocomelon – Nursery Rhymes        May 2, 2018  4.29  \n",
       "7                      Miroshka TV  February 27, 2018  4.25  \n",
       "8                      Mark Ronson  November 19, 2014  4.22  \n",
       "9                              Psy      July 15, 2012  4.11  \n",
       "10                       ChuChu TV      March 6, 2014  3.98  \n",
       "11                        Maroon 5   January 14, 2015  3.50  \n",
       "12                       El Chombo      April 5, 2018  3.45  \n",
       "13                   Justin Bieber   October 22, 2015  3.45  \n",
       "14                      Katy Perry  September 5, 2013  3.38  \n",
       "15                     OneRepublic       May 31, 2013  3.34  \n",
       "16                      Ed Sheeran    October 7, 2014  3.29  \n",
       "17      Cocomelon – Nursery Rhymes       May 24, 2018  3.15  \n",
       "18                      Katy Perry  February 20, 2014  3.10  \n",
       "19                     Alan Walker   December 3, 2015  3.10  \n",
       "20                    Taylor Swift    August 18, 2014  3.07  \n",
       "21                        Maroon 5       May 31, 2018  3.07  \n",
       "22                     Major Lazer     March 22, 2015  3.06  \n",
       "23                Enrique Iglesias     April 11, 2014  3.06  \n",
       "24                       Passenger      July 25, 2012  3.02  \n",
       "25                        J Balvin      June 29, 2017  2.94  \n",
       "26                      Ed Sheeran   November 9, 2017  2.89  \n",
       "27                         Shakira       June 4, 2010  2.88  \n",
       "28                      Crazy Frog      June 16, 2009  2.87  \n",
       "29                           Adele   October 22, 2015  2.85  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostviewed = mostviewed_videos() #Calling the function and assigning to a variable\n",
    "mostviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "    \n",
    "You need to find following details:\n",
    "    \n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def India_fixtures():\n",
    "    \"\"\"Creating function that searches details of Team India International Fixtures\"\"\"\n",
    "\n",
    "    template = 'https://www.bcci.tv/.' #URL template for accessing the website\n",
    "    driver = webdriver.Chrome(executable_path=\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver\n",
    "    driver.get(template) #Opening with the URL template\n",
    "    driver.maximize_window() #Maximize the Window\n",
    "    \n",
    "    time.sleep(5) #Making the Function wait for 5sec so webpage will open\n",
    "    \n",
    "    #Creating a variable \"Button\" to search the Fixtures and getting the 'href' to open in the driver.\n",
    "    button = driver.find_element_by_xpath(\"//div[@class = 'navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")\n",
    "    driver.get(button.get_attribute(\"href\"))\n",
    "    \n",
    "    time.sleep(5) #Making the Function wait for 5sec so webpage will open\n",
    "    \n",
    "    Match_title = [] #Creating Variable Match title to collect the title of the match i.e. Test or ODI.\n",
    "    Series = [] #Creating Variable Series to collect the Series name. \n",
    "    Place = [] #Creating variable Place to collect the Match venue.\n",
    "    Date = [] #Creating Variable Date to collect the venue Date.\n",
    "    Time = [] #Creating Variable Time to collect the venue Time.\n",
    "    details = [] #Creating a Dummy variable Details to collect the Date and time details\n",
    "    \n",
    "    #Scraping Match Details and appending in the Match list.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__format-strip']/ span [@class = 'u-unskewed-text fixture__format']\"):\n",
    "        Match_title.append(i.text)\n",
    "\n",
    "    #Scraping Series Details and appending in the Series list.    \n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__format-strip']/ span [@class = 'u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "        Series.append(i.text)\n",
    "    \n",
    "    #Scraping Place Details and appending in the Place list.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__description u-unskewed-text']/p/span\"):\n",
    "        Place.append(i.text)\n",
    "    \n",
    "    #Scraping Date and Time Details and appending in the details list.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__datetime desktop-only']\"):\n",
    "        details.append(i.text.replace('\\n',' '))\n",
    "        \n",
    "    driver.close() #Exiting the driver post scraping the information    \n",
    "    \n",
    "    #Spliting the details list and sorting it in Date and Time. \n",
    "    Date = [i.split(' ',3)[:3]for i in details]\n",
    "    Date = [' '.join(i) for i in Date]\n",
    "    Time = [i.split(' ',3)[-1]for i in details]\n",
    "    \n",
    "    #Creating the DataFrame from all collected data\n",
    "    Fixtures = pd.DataFrame({'Match title' : Match_title , \n",
    "                             'Series' : Series , \n",
    "                             'Place' : Place, \n",
    "                             'Date' : Date ,\n",
    "                             'Time' : Time})\n",
    "    \n",
    "    return Fixtures #returns the DataFrame with collected details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Sunday 18 JULY</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Tuesday 20 JULY</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Friday 23 JULY</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Sunday 25 JULY</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Tuesday 27 JULY</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Thursday 29 JULY</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>Wednesday 04 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>Thursday 12 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>Wednesday 25 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>Thursday 02 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>Friday 10 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match title                  Series                         Place  \\\n",
       "0          ODI  SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "1          ODI  SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "2          ODI  SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "3         T20I  SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "4         T20I  SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "5         T20I  SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "6         TEST    ENGLAND V INDIA 2021      Trent Bridge, Nottingham   \n",
       "7         TEST    ENGLAND V INDIA 2021                Lord's, London   \n",
       "8         TEST    ENGLAND V INDIA 2021             Headingley, Leeds   \n",
       "9         TEST    ENGLAND V INDIA 2021              The Oval, London   \n",
       "10        TEST    ENGLAND V INDIA 2021      Old Trafford, Manchester   \n",
       "\n",
       "                     Date       Time  \n",
       "0          Sunday 18 JULY  15:00 IST  \n",
       "1         Tuesday 20 JULY  15:00 IST  \n",
       "2          Friday 23 JULY  15:00 IST  \n",
       "3          Sunday 25 JULY  20:00 IST  \n",
       "4         Tuesday 27 JULY  20:00 IST  \n",
       "5        Thursday 29 JULY  20:00 IST  \n",
       "6     Wednesday 04 AUGUST  15:30 IST  \n",
       "7      Thursday 12 AUGUST  15:30 IST  \n",
       "8     Wednesday 25 AUGUST  15:30 IST  \n",
       "9   Thursday 02 SEPTEMBER  15:30 IST  \n",
       "10    Friday 10 SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "India_fixtures()#Calling the function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Selenium_exp_handeling():\n",
    "    \"\"\"Creating function that searches details of most viewed videos on YouTube from Wikipedia\"\"\"\n",
    "\n",
    "    template = 'https://www.guru99.com' #URL template for accessing the website.\n",
    "    driver = webdriver.Chrome(executable_path=\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    href = [] #Creating a variable to collect the href details of Selenium.\n",
    "    for i in driver.find_elements_by_xpath(\"//li [@class = 'fa fa-chevron-circle-right']/a\"):\n",
    "        if i.text == 'Selenium':\n",
    "            href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[0]) #Opening the Driver with the href details.\n",
    "    \n",
    "    #Finding the 'Selenium Exception Handling' tutorial and clicking.\n",
    "    tutorial = driver.find_element_by_xpath(\"//td [@class = 'responsivetable']/a [@title = 'Selenium Exception Handling (Common Exceptions List)']\")\n",
    "    tutorial.click()\n",
    "    \n",
    "    time.sleep(3)#Making the Function wait for 3sec so webpage will open.\n",
    "\n",
    "    details = [] #Creating a Variable name Details to collect the Details of Name and Description Note.\n",
    "    \n",
    "    #Scraping the Details of Name and Description Note and storing it in the details.\n",
    "    for i in driver.find_elements_by_xpath(\"//table [@class = 'table table-striped']/tbody\"):\n",
    "        details.append(i.text)\n",
    "    \n",
    "    driver.close()#Closing the Driver post collecting the informations.\n",
    "    \n",
    "    #Splitting the Details list and storing it in name and Description_Note.\n",
    "    details =  [i.split('\\n') for i in details]\n",
    "    \n",
    "    details = details[0]\n",
    "    details.remove('Exception name Description')\n",
    "    \n",
    "    Name =  [i.split(' ',1)[0] for i in details]\n",
    "    Description_Note = [i.split(' ',1)[-1] for i in details]\n",
    "    \n",
    "    #Creating the DataFrame from all collected data.\n",
    "    exception_handeling = pd.DataFrame({'Name' : Name,\n",
    "                                        'Description Note' : Description_Note})\n",
    "    \n",
    "    return exception_handeling #returns the DataFrame with collected details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0      ElementNotVisibleException   \n",
       "1   ElementNotSelectableException   \n",
       "2          NoSuchElementException   \n",
       "3            NoSuchFrameException   \n",
       "4         NoAlertPresentException   \n",
       "5           NoSuchWindowException   \n",
       "6  StaleElementReferenceException   \n",
       "7        SessionNotFoundException   \n",
       "8                TimeoutException   \n",
       "9              WebDriverException   \n",
       "\n",
       "                                    Description Note  \n",
       "0  This type of Selenium exception occurs when an...  \n",
       "1  This Selenium exception occurs when an element...  \n",
       "2  This Exception occurs if an element could not ...  \n",
       "3  This Exception occurs if the frame target to b...  \n",
       "4  This Exception occurs when you switch to no pr...  \n",
       "5  This Exception occurs if the window target to ...  \n",
       "6  This Selenium exception occurs happens when th...  \n",
       "7  The WebDriver is acting after you quit the bro...  \n",
       "8  Thrown when there is not enough time for a com...  \n",
       "9  This Exception takes place when the WebDriver ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exeptions = Selenium_exp_handeling() #Calling the Function and storing it in a variable.\n",
    "exeptions.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def State_wise_GDP():\n",
    "    \"\"\"Creating function that searches details of India State_wise_GDP\"\"\"\n",
    "    \n",
    "    template = 'http://statisticstimes.com/'#URL template for accessing the website.\n",
    "    driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'dropdown']/div [@class = 'dropdown-content']/a\"):\n",
    "        href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[4]) #opening the href[4] which is GDP of India.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details of GDP of Indian states.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@style = 'float:left;background-color:seashell;width:400px;height:800px;']/ul [@style = 'list-style-type:none;margin-left:20px;']/li/a\"):\n",
    "        if i.text == '» GDP of Indian states':\n",
    "            href.append(i.get_attribute('href'))\n",
    "    \n",
    "    driver.get(href[0]) #opening the href[4] which is GDP of Indian states.\n",
    "    \n",
    "    Rank = [] #Declaring Rank list to collect the Rank details\n",
    "    State = [] #Declaring State list to collect the State details\n",
    "    GSDP20 = [] #Declaring GSDP20 list to collect the GSDP20 details\n",
    "    GSDP19 = [] #Declaring GSDP19 list to collect the GSDP19 details\n",
    "    Share = [] #Declaring Share list to collect the Share details\n",
    "    GDP = [] #Declaring GDP list to collect the GDP details\n",
    "\n",
    "    details = [] #scraping all the above mentioned details and storing it in the details list.\n",
    "    for i in driver.find_elements_by_xpath(\"//tbody /tr [@role = 'row']/td\"):\n",
    "        details.append(i.text)\n",
    "    \n",
    "    driver.close() #Exiting the Driver post collecting all the details.\n",
    "    \n",
    "    details = details[:264] #Sorting the list with the required details.\n",
    "    \n",
    "    z= 0\n",
    "    while z < len(details): # Splitting the collected details and storing it in the required list.\n",
    "        Rank.append(details[z])\n",
    "        z+=1\n",
    "        State.append(details[z])\n",
    "        z+=1\n",
    "        GSDP20.append(details[z])\n",
    "        z+=1\n",
    "        GSDP19.append(details[z])\n",
    "        z+=1\n",
    "        Share.append(details[z])\n",
    "        z+=1\n",
    "        GDP.append(details[z])\n",
    "        z+=3\n",
    "    \n",
    "    #Creating a DataFrame with collected details.\n",
    "    table = pd.DataFrame({\"Rank\" : Rank,\n",
    "                          \"State\" : State,\n",
    "                          \"GSDP(19-20)\" : GSDP20,\n",
    "                          \"GSDP(18-19)\" : GSDP19,\n",
    "                          \"Share(2018)\" : Share,\n",
    "                          \"GDP($ billion)\": GDP})\n",
    "    \n",
    "    return table #returing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(2018)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank           State GSDP(19-20) GSDP(18-19) Share(2018) GDP($ billion)\n",
       "0    1     Maharashtra           -   2,632,792      13.94%        399.921\n",
       "1    2      Tamil Nadu   1,845,853   1,630,208       8.63%        247.629\n",
       "2    3   Uttar Pradesh   1,687,818   1,584,764       8.39%        240.726\n",
       "3    4         Gujarat           -   1,502,899       7.96%        228.290\n",
       "4    5       Karnataka   1,631,977   1,493,127       7.91%        226.806\n",
       "5    6     West Bengal   1,253,832   1,089,898       5.77%        165.556\n",
       "6    7       Rajasthan   1,020,989     942,586       4.99%        143.179\n",
       "7    8  Andhra Pradesh     972,782     862,957       4.57%        131.083\n",
       "8    9       Telangana     969,604     861,031       4.56%        130.791\n",
       "9   10  Madhya Pradesh     906,672     809,592       4.29%        122.977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP = State_wise_GDP() #Calling the function and storing it in a variable.\n",
    "GDP.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https://github.com/'\n",
    "driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\")\n",
    "# Let's activate and load the chrome browser\n",
    "\n",
    "driver.maximize_window()\n",
    "driver.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Import required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "# Let's navigate to the trending option and click on it\n",
    "trending=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create an empty lists to store scraping data\n",
    "Repository_Title=[]\n",
    "Repository_Description=[] \n",
    "Contributors_Count=[] \n",
    "Language_Used=[]\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 22 25 25\n"
     ]
    }
   ],
   "source": [
    "# Let's create a function\n",
    "rep_title=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/h1/a')\n",
    "descriptions=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/p')\n",
    "for i in [rep_title,descriptions]:\n",
    "    for j in i:\n",
    "        if i ==rep_title:\n",
    "            Repository_Title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==descriptions:\n",
    "            Repository_Description.append(j.text)\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    div_list=driver.find_elements_by_xpath('//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    try:\n",
    "        Contributors_Count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_Count.append('-')\n",
    "    try:\n",
    "        Language_Used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_Used.append('-')\n",
    "\n",
    "# Let's check the length of the scrape data        \n",
    "print(len(Repository_Title),len(Repository_Description),len(Contributors_Count),len(Language_Used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bndw / wifi-card</td>\n",
       "      <td>Print a QR code for connecting to your WiFi</td>\n",
       "      <td>7</td>\n",
       "      <td>[JavaScript, HTML, CSS, Makefile, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>580</td>\n",
       "      <td>[C++, Python, CMake, C, Shell, Assembly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft / IoT-For-Beginners</td>\n",
       "      <td>12 Weeks, 24 Lessons, IoT for All!</td>\n",
       "      <td>26</td>\n",
       "      <td>[C++, Python, C, Jupyter, 2.1%, 2.1%, 2.0%, 1.0%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NationalSecurityAgency / ghidra</td>\n",
       "      <td>Ghidra is a software reverse engineering (SRE)...</td>\n",
       "      <td>149</td>\n",
       "      <td>[Java, C++, HTML, C, Python, Shell, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / CBL-Mariner</td>\n",
       "      <td>Linux OS for Azure 1P services and edge applia...</td>\n",
       "      <td>37</td>\n",
       "      <td>[Go, Shell, C, Makefile, Roff, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opensearch-project / OpenSearch</td>\n",
       "      <td>Open source distributed and RESTful search eng...</td>\n",
       "      <td>46</td>\n",
       "      <td>[Java, Groovy, Shell, Batchfile, ANTLR, Docker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avelino / awesome-go</td>\n",
       "      <td>A curated list of awesome Go frameworks, libra...</td>\n",
       "      <td>1,489</td>\n",
       "      <td>[Go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fenixsoft / awesome-fenix</td>\n",
       "      <td>讨论如何构建一套可靠的大型分布式系统</td>\n",
       "      <td>8</td>\n",
       "      <td>[Vue, JavaScript, Stylus, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dromara / Sa-Token</td>\n",
       "      <td>这可能是史上功能最全的Java权限认证框架！目前已集成——登录认证、权限认证、分布式Sess...</td>\n",
       "      <td>20</td>\n",
       "      <td>[Java, HTML, CSS, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0vercl0k / wtf</td>\n",
       "      <td>wtf is a distributed, code-coverage guided, cu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[C++, Assembly, Rust, Python, C, CMake, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TencentARC / GFPGAN</td>\n",
       "      <td>12 weeks, 24 lessons, classic Machine Learning...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>microsoft / ML-For-Beginners</td>\n",
       "      <td>专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！</td>\n",
       "      <td>35</td>\n",
       "      <td>[Jupyter, 99.4%, 0.6%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chefyuan / algorithm-base</td>\n",
       "      <td>End-to-end image segmentation kit based on Pad...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PaddlePaddle / PaddleSeg</td>\n",
       "      <td>微信消息解密工具</td>\n",
       "      <td>47</td>\n",
       "      <td>[Python, Java, C++, CMake, Dockerfile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JustYoomoon / WechatDecrypt</td>\n",
       "      <td> Now we have become very big, Different from ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[C++]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jaywcjlove / awesome-mac</td>\n",
       "      <td>GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜单每周...</td>\n",
       "      <td>358</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kon9chunkit / GitHub-Chinese-Top-Charts</td>\n",
       "      <td>Used to integrate the Facebook Platform with y...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>facebook / facebook-ios-sdk</td>\n",
       "      <td>A Go framework for microservices.</td>\n",
       "      <td>117</td>\n",
       "      <td>[Objective-C, Swift, Objective-C++, Shell, Rub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>go-kratos / kratos</td>\n",
       "      <td>A cat(1) clone with wings.</td>\n",
       "      <td>104</td>\n",
       "      <td>[Go, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sharkdp / bat</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>236</td>\n",
       "      <td>[Rust, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Aaron-lv / sync</td>\n",
       "      <td>Model parallel transformers in JAX and Haiku</td>\n",
       "      <td>No</td>\n",
       "      <td>[No, published]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AkashSingh3031 / The-Complete-FAANG-Preparation</td>\n",
       "      <td>An open source vector database powered by Fais...</td>\n",
       "      <td>33</td>\n",
       "      <td>[Jupyter, 71.2%, 8.8%, 5.6%, 5.5%, 3.1%, 2.9%,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Repository Title  \\\n",
       "0                                  bndw / wifi-card   \n",
       "1                                  facebook / folly   \n",
       "2                     microsoft / IoT-For-Beginners   \n",
       "3                   NationalSecurityAgency / ghidra   \n",
       "4                           microsoft / CBL-Mariner   \n",
       "5                   opensearch-project / OpenSearch   \n",
       "6                              avelino / awesome-go   \n",
       "7                         fenixsoft / awesome-fenix   \n",
       "8                                dromara / Sa-Token   \n",
       "9                                    0vercl0k / wtf   \n",
       "10                              TencentARC / GFPGAN   \n",
       "11                     microsoft / ML-For-Beginners   \n",
       "12                        chefyuan / algorithm-base   \n",
       "13                         PaddlePaddle / PaddleSeg   \n",
       "14                      JustYoomoon / WechatDecrypt   \n",
       "15                         jaywcjlove / awesome-mac   \n",
       "16          kon9chunkit / GitHub-Chinese-Top-Charts   \n",
       "17                      facebook / facebook-ios-sdk   \n",
       "18                               go-kratos / kratos   \n",
       "19                                    sharkdp / bat   \n",
       "20                                  Aaron-lv / sync   \n",
       "21  AkashSingh3031 / The-Complete-FAANG-Preparation   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0         Print a QR code for connecting to your WiFi                  7   \n",
       "1   An open-source C++ library developed and used ...                580   \n",
       "2                  12 Weeks, 24 Lessons, IoT for All!                 26   \n",
       "3   Ghidra is a software reverse engineering (SRE)...                149   \n",
       "4   Linux OS for Azure 1P services and edge applia...                 37   \n",
       "5   Open source distributed and RESTful search eng...                 46   \n",
       "6   A curated list of awesome Go frameworks, libra...              1,489   \n",
       "7                                  讨论如何构建一套可靠的大型分布式系统                  8   \n",
       "8   这可能是史上功能最全的Java权限认证框架！目前已集成——登录认证、权限认证、分布式Sess...                 20   \n",
       "9   wtf is a distributed, code-coverage guided, cu...                  2   \n",
       "10  12 weeks, 24 lessons, classic Machine Learning...                  -   \n",
       "11   专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！                 35   \n",
       "12  End-to-end image segmentation kit based on Pad...                  6   \n",
       "13                                           微信消息解密工具                 47   \n",
       "14   Now we have become very big, Different from ...                  -   \n",
       "15  GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜单每周...                358   \n",
       "16  Used to integrate the Facebook Platform with y...                  -   \n",
       "17                  A Go framework for microservices.                117   \n",
       "18                         A cat(1) clone with wings.                104   \n",
       "19  This repository contains all the DSA (Data-Str...                236   \n",
       "20       Model parallel transformers in JAX and Haiku                 No   \n",
       "21  An open source vector database powered by Fais...                 33   \n",
       "\n",
       "                                        Language Used  \n",
       "0       [JavaScript, HTML, CSS, Makefile, Dockerfile]  \n",
       "1            [C++, Python, CMake, C, Shell, Assembly]  \n",
       "2   [C++, Python, C, Jupyter, 2.1%, 2.1%, 2.0%, 1.0%]  \n",
       "3          [Java, C++, HTML, C, Python, Shell, Other]  \n",
       "4       [Go, Shell, C, Makefile, Roff, Python, Other]  \n",
       "5   [Java, Groovy, Shell, Batchfile, ANTLR, Docker...  \n",
       "6                                                [Go]  \n",
       "7                    [Vue, JavaScript, Stylus, Shell]  \n",
       "8                            [Java, HTML, CSS, Other]  \n",
       "9      [C++, Assembly, Rust, Python, C, CMake, Other]  \n",
       "10                                           [Python]  \n",
       "11                             [Jupyter, 99.4%, 0.6%]  \n",
       "12                                             [Java]  \n",
       "13      [Python, Java, C++, CMake, Dockerfile, Shell]  \n",
       "14                                              [C++]  \n",
       "15                                       [JavaScript]  \n",
       "16                                             [Java]  \n",
       "17  [Objective-C, Swift, Objective-C++, Shell, Rub...  \n",
       "18                                     [Go, Makefile]  \n",
       "19                              [Rust, Python, Other]  \n",
       "20                                    [No, published]  \n",
       "21  [Jupyter, 71.2%, 8.8%, 5.6%, 5.5%, 3.1%, 2.9%,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create the dataframe from the scraped data\n",
    "Repository=pd.DataFrame({})\n",
    "Repository['Repository Title']=Repository_Title[0:22]\n",
    "Repository['Repository Description']=Repository_Description[0:22]\n",
    "Repository['Contributors Count']=Contributors_Count[0:22]\n",
    "Repository['Language Used']=Language_Used[0:22]\n",
    "Repository"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_100():\n",
    "    \"\"\"Creating function that searches details of top 100 songs from billboard\"\"\"\n",
    "    \n",
    "    template = 'https://www.billboard.com/'#URL template for accessing the website.\n",
    "    driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\")#Calling the Web Driver.\n",
    "    driver.get(template)#Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    \n",
    "    href = []#Creating href list to collect \"HOT 100\" href details.\n",
    "    for i in driver.find_elements_by_xpath(\"//li [@class = 'header__subnav__item']/a\"):\n",
    "        if i.text == 'HOT 100':\n",
    "            href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[0])# Opening the Driver with the collected href detail.\n",
    "    \n",
    "    #Scraping the Song_name and storing it in the Song_name list.\n",
    "    Song_name = [i.text for i in driver.find_elements_by_xpath(\"// span [@class ='chart-element__information']/span[@ class= 'chart-element__information__song text--truncate color--primary']\")]\n",
    "    \n",
    "    #Scraping the Artist_name and storing it in the Artist_name list.\n",
    "    Artist_name = [i.text for i in driver.find_elements_by_xpath(\"// span [@class ='chart-element__information']/span[@ class= 'chart-element__information__artist text--truncate color--secondary']\")]\n",
    "    \n",
    "    #Scraping the Last_week_rank and storing it in the Last_week_rank list.\n",
    "    Last_week_rank = [i.text for i in driver.find_elements_by_xpath(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--last']\")]\n",
    "    \n",
    "    #Scraping the Peak_rank and storing it in the Peak_rank list.\n",
    "    Peak_rank = [i.text for i in driver.find_elements_by_xpath(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--peak']\")]\n",
    "    \n",
    "    #Scraping the Weeks_on_board and storing it in the Weeks_on_board list.\n",
    "    Weeks_on_board = [i.text for i in driver.find_elements_by_xpath(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--week']\")]\n",
    "    \n",
    "    driver.close()#Quiting the Driver post Scraping the Details Required.\n",
    "\n",
    "    #Creating a DataFrame withe the collected Details.\n",
    "    table = pd.DataFrame({\"Song_name\" : Song_name,\n",
    "                          \"Artist_name\" : Artist_name,\n",
    "                          \"Last_week_rank\" : Last_week_rank,\n",
    "                          \"Peak_rank\" : Peak_rank,\n",
    "                          \"Weeks_on_board\": Weeks_on_board})\n",
    "    \n",
    "    return table #Retuting the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montero (Call Me By Your Name)</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bad Habits</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deja Vu</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Song_name  \\\n",
       "0                          Butter   \n",
       "1                        Good 4 U   \n",
       "2                      Levitating   \n",
       "3                    Kiss Me More   \n",
       "4  Montero (Call Me By Your Name)   \n",
       "5                      Bad Habits   \n",
       "6             Leave The Door Open   \n",
       "7                         Peaches   \n",
       "8                 Save Your Tears   \n",
       "9                         Deja Vu   \n",
       "\n",
       "                                      Artist_name Last_week_rank Peak_rank  \\\n",
       "0                                             BTS              1         1   \n",
       "1                                  Olivia Rodrigo              2         1   \n",
       "2                       Dua Lipa Featuring DaBaby              4         2   \n",
       "3                          Doja Cat Featuring SZA              3         3   \n",
       "4                                       Lil Nas X              8         1   \n",
       "5                                      Ed Sheeran              5         5   \n",
       "6        Silk Sonic (Bruno Mars & Anderson .Paak)              6         1   \n",
       "7  Justin Bieber Featuring Daniel Caesar & Giveon              7         1   \n",
       "8                      The Weeknd & Ariana Grande              9         1   \n",
       "9                                  Olivia Rodrigo             10         3   \n",
       "\n",
       "  Weeks_on_board  \n",
       "0              7  \n",
       "1              8  \n",
       "2             40  \n",
       "3             13  \n",
       "4             15  \n",
       "5              2  \n",
       "6             18  \n",
       "7             16  \n",
       "8             30  \n",
       "9             14  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100songs = top_100() #Calling the Function and assigning it to a variable.\n",
    "top_100songs.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naukri_Recruiters():\n",
    "    \"\"\"Creating function that searches details of recruiters from Naukri.com\"\"\"\n",
    "    \n",
    "    template = 'https://www.naukri.com/' #URL template for accessing the website.\n",
    "    driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    #Creating the variable Recruiters to search and find the Xpath of Recruiters.\n",
    "    Recruiters = driver.find_element_by_xpath(\"//li/a [@title = 'Search Recruiters']\") \n",
    "    href= Recruiters.get_attribute('href') #Creating the variable href to search and find the href of Recruiters.\n",
    "    driver.get(href) #Opening web-Driver with href.\n",
    "    \n",
    "    #Searching the input key and sending the key as Data Science.\n",
    "    search = driver.find_element_by_xpath(\"//div[@class= 'inpWrap']/ input [@class = 'sugInp']\")\n",
    "    search.send_keys(\"Data science\")\n",
    "    \n",
    "    #Searching the search Button and Clicking it.\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'fl qsbSrch blueBtn']\")\n",
    "    search_btn.click()\n",
    "    \n",
    "    #Creating a dummy list and storing details of name and Company of Recuriters.\n",
    "    dummy = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='highlightable']//a[@class = 'ellipsis']\")]\n",
    "    \n",
    "    #Creating href list and storing details of href of Recuriters.\n",
    "    href = [i.get_attribute('href') for i in driver.find_elements_by_xpath(\"//p [@class ='highlightable']//a[@class = 'ellipsis']\")]\n",
    "    \n",
    "    #Creating Designation list and storing details of Designation of Recuriters.\n",
    "    Designation = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='highlightable']//span[@ class= 'ellipsis clr']\")]\n",
    "    \n",
    "    #Creating skills list and storing details of skills of Recuriters.\n",
    "    skills = [i.text for i in driver.find_elements_by_xpath(\"//div [@class ='recInfo']//div[@ class= 'hireSec highlightable']\")]\n",
    "\n",
    "\n",
    "    Name = []#Creating a Name list to collect names of recuriters.\n",
    "    company = []#Creating a company list to collect company of recuriters.\n",
    "    Href = []#Creating a Href list to collect href of recuriters.\n",
    "    \n",
    "    z = 0 #Spliting dummy and href and storing it in the appropiate list.\n",
    "    while z < len(dummy):\n",
    "        Name.append(dummy[z])\n",
    "        Href.append(href[z])\n",
    "        z+=1\n",
    "        company.append(dummy[z])\n",
    "        z+=1\n",
    "    \n",
    "    Location = [] #creating the Location list to store all the location of the recuriters.\n",
    "    for i in Href: #iterating Href to collect the location details.\n",
    "        driver.get(i)    \n",
    "        loc = [i.text for i in driver.find_elements_by_xpath(\"//div [@class ='oh']/a[@ target= '_blank']\")]\n",
    "        loc = loc[-1]\n",
    "        if loc == 'Others':\n",
    "            Location.append('-')\n",
    "        elif loc:\n",
    "            Location.append(loc)\n",
    "        else:\n",
    "            Location.append('-')\n",
    "   \n",
    "    driver.quit()#exiting the driver post scraping the information\n",
    "    \n",
    "    #Creating a DataFrame with all collected details.\n",
    "    table = pd.DataFrame({\"Name\" : Name,\n",
    "                          \"Company\" : company,\n",
    "                          \"Designation\" : Designation,\n",
    "                          \"Location\" : Location,\n",
    "                          \"skills\": skills})\n",
    "    \n",
    "    return table #returning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Location</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Director</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "0                                   Aakash Harit   \n",
       "1                           shravan Kumar Gaddam   \n",
       "2                       MARSIAN Technologies LLP   \n",
       "3                                   Anik Agrawal   \n",
       "4                                   subhas patel   \n",
       "5   Abhishek - Only Analytics Hiring - India and   \n",
       "6  Institute for Financial Management and Resear   \n",
       "7                                    Balu Ramesh   \n",
       "8                                  Asif Lucknowi   \n",
       "9                                InstaFinancials   \n",
       "\n",
       "                                      Company                  Designation  \\\n",
       "0                        Data Science Network                   HR Manager   \n",
       "1               Shore Infotech India Pvt. Ltd            Company Recruiter   \n",
       "2                    MARSIAN Technologies LLP                   Company HR   \n",
       "3       Enerlytics Software Solutions Pvt Ltd            Company Recruiter   \n",
       "4                             LibraryXProject                  Founder CEO   \n",
       "5  Apidel Technologies Division of Transpower  Recruitment Lead Consultant   \n",
       "6                                        IFMR            Programme Manager   \n",
       "7                 Techvantage Systems Pvt Ltd             HR Administrator   \n",
       "8                  Weupskill- Live Wire India                     Director   \n",
       "9            CBL Data Science Private Limited               Human Resource   \n",
       "\n",
       "                   Location                                             skills  \n",
       "0                     Delhi  Classic ASP Developer, Internet Marketing Prof...  \n",
       "1  Hyderabad / Secunderabad  .Net, Java, Data Science, Linux Administration...  \n",
       "2                      Pune  Data Science, Artificial Intelligence, Machine...  \n",
       "3                 Ahmedabad  Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4             UK - (london)  Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5         Vadodara / Baroda  Analytics, Business Intelligence, Business Ana...  \n",
       "6                   Chennai                                       Data Science  \n",
       "7                Trivandrum  Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8                    Indore  Technical Training, Software Development, Pres...  \n",
       "9     Bengaluru / Bangalore  Software Development, It Sales, Account Manage...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recruiters = Naukri_Recruiters() #calling function and storing it in a variable.\n",
    "Recruiters.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-\n",
    "compare/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Highest_selling_novels():\n",
    "    \"\"\"The Function which searches and returns top selling novels from theguardian.com\"\"\"\n",
    "    \n",
    "    #URL template for accessing the website.\n",
    "    template = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "    driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\")#Calling the Web Driver.\n",
    "    driver.get(template)#Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    \n",
    "    #Creating a dummy list and scraping the all the required details.\n",
    "    dummy = [i.text for i in driver.find_elements_by_xpath(\"//table [@class ='in-article sortable']//tr/td\")]\n",
    "    \n",
    "    driver.close() #Quiting the driver post collecting the details. \n",
    "    \n",
    "    dummy.remove('SOURCE: NIELSEN BOOK SCAN') #Removing the unwanted details from dummy list. \n",
    "\n",
    "    Book_name = [] #Creating list Book_name to collect the Book_name details.\n",
    "    Author_name = [] #Creating list Author_name to collect the Author_name details.\n",
    "    Volumes_sold = [] #Creating list Volumes_sold to collect the Volumes_sold details.\n",
    "    Publisher = [] #Creating list Publisher to collect the Publisher details.\n",
    "    Genre = [] #Creating list Genre to collect the Genre details.\n",
    "\n",
    "    z = 0\n",
    "    while z < len(dummy): #Splitting dummy list and storing the required details it in the appropriate list.\n",
    "        z+=1\n",
    "        Book_name.append(dummy[z])\n",
    "        z+=1\n",
    "        Author_name.append(dummy[z])\n",
    "        z+=1\n",
    "        Volumes_sold.append(dummy[z])\n",
    "        z+=1\n",
    "        Publisher.append(dummy[z])\n",
    "        z+=1\n",
    "        Genre.append(dummy[z])\n",
    "        z+=1\n",
    "    \n",
    "    #Creating the DataFrame with all the collected details.\n",
    "    table = pd.DataFrame({\"Book_name\" : Book_name,\n",
    "                          \"Author_name\" : Author_name,\n",
    "                          \"Volumes_sold\" : Volumes_sold,\n",
    "                          \"Publisher\" : Publisher,\n",
    "                          \"Genre\": Genre})\n",
    "    \n",
    "    return table #returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,583,215</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,484,047</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,377,906</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angels and Demons</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>3,193,946</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harry Potter and the Half-blood Prince:Childre...</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>2,950,264</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fifty Shades Darker</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,479,784</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,315,405</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Girl with the Dragon Tattoo,The:Millennium Tri...</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>2,233,570</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fifty Shades Freed</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,193,928</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lost Symbol,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,183,031</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,152,737</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Deception Point</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,062,145</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eclipse</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,052,876</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lovely Bones,The</td>\n",
       "      <td>Sebold, Alice</td>\n",
       "      <td>2,005,598</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Curious Incident of the Dog in the Night-time,The</td>\n",
       "      <td>Haddon, Mark</td>\n",
       "      <td>1,979,552</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Digital Fortress</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>1,928,900</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Short History of Nearly Everything,A</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>1,852,919</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Girl Who Played with Fire,The:Millennium Trilogy</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>1,814,784</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Breaking Dawn</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>1,787,118</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Very Hungry Caterpillar,The:The Very Hungry Ca...</td>\n",
       "      <td>Carle, Eric</td>\n",
       "      <td>1,783,535</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gruffalo,The</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>1,781,269</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Jamie's 30-Minute Meals</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>1,743,266</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kite Runner,The</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,629,119</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>One Day</td>\n",
       "      <td>Nicholls, David</td>\n",
       "      <td>1,616,068</td>\n",
       "      <td>Hodder &amp; Stoughton</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thousand Splendid Suns,A</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,583,992</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Girl Who Kicked the Hornets' Nest,The:Millenni...</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>1,555,135</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Time Traveler's Wife,The</td>\n",
       "      <td>Niffenegger, Audrey</td>\n",
       "      <td>1,546,886</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Atonement</td>\n",
       "      <td>McEwan, Ian</td>\n",
       "      <td>1,539,428</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bridget Jones's Diary:A Novel</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>1,508,205</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>World According to Clarkson,The</td>\n",
       "      <td>Clarkson, Jeremy</td>\n",
       "      <td>1,489,403</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Humour: Collections &amp; General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>Bernieres, Louis de</td>\n",
       "      <td>1,352,318</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sound of Laughter,The</td>\n",
       "      <td>Kay, Peter</td>\n",
       "      <td>1,310,207</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Life of Pi</td>\n",
       "      <td>Martel, Yann</td>\n",
       "      <td>1,310,176</td>\n",
       "      <td>Canongate</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Billy Connolly</td>\n",
       "      <td>Stephenson, Pamela</td>\n",
       "      <td>1,231,957</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Biography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Child Called It,A</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>1,217,712</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Gruffalo's Child,The</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>1,208,711</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Angela's Ashes:A Memoir of a Childhood</td>\n",
       "      <td>McCourt, Frank</td>\n",
       "      <td>1,204,058</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Birdsong</td>\n",
       "      <td>Faulks, Sebastian</td>\n",
       "      <td>1,184,967</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Northern Lights:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,181,503</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Labyrinth</td>\n",
       "      <td>Mosse, Kate</td>\n",
       "      <td>1,181,093</td>\n",
       "      <td>Orion</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Harry Potter and the Half-blood Prince</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>1,153,181</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Help,The</td>\n",
       "      <td>Stockett, Kathryn</td>\n",
       "      <td>1,132,336</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Man and Boy</td>\n",
       "      <td>Parsons, Tony</td>\n",
       "      <td>1,130,802</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Memoirs of a Geisha</td>\n",
       "      <td>Golden, Arthur</td>\n",
       "      <td>1,126,337</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>No.1 Ladies' Detective Agency,The:No.1 Ladies'...</td>\n",
       "      <td>McCall Smith, Alexander</td>\n",
       "      <td>1,115,549</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Island,The</td>\n",
       "      <td>Hislop, Victoria</td>\n",
       "      <td>1,108,328</td>\n",
       "      <td>Headline</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PS, I Love You</td>\n",
       "      <td>Ahern, Cecelia</td>\n",
       "      <td>1,107,379</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>You are What You Eat:The Plan That Will Change...</td>\n",
       "      <td>McKeith, Gillian</td>\n",
       "      <td>1,104,403</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Shadow of the Wind,The</td>\n",
       "      <td>Zafon, Carlos Ruiz</td>\n",
       "      <td>1,092,349</td>\n",
       "      <td>Orion</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Tales of Beedle the Bard,The</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>1,090,847</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Broker,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>1,087,262</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Dr. Atkins' New Diet Revolution:The No-hunger,...</td>\n",
       "      <td>Atkins, Robert C.</td>\n",
       "      <td>1,054,196</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Subtle Knife,The:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,037,160</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Eats, Shoots and Leaves:The Zero Tolerance App...</td>\n",
       "      <td>Truss, Lynne</td>\n",
       "      <td>1,023,688</td>\n",
       "      <td>Profile Books Group</td>\n",
       "      <td>Usage &amp; Writing Guides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Delia's How to Cook:(Bk.1)</td>\n",
       "      <td>Smith, Delia</td>\n",
       "      <td>1,015,956</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Chocolat</td>\n",
       "      <td>Harris, Joanne</td>\n",
       "      <td>1,009,873</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Boy in the Striped Pyjamas,The</td>\n",
       "      <td>Boyne, John</td>\n",
       "      <td>1,004,414</td>\n",
       "      <td>Random House Childrens Books G</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>My Sister's Keeper</td>\n",
       "      <td>Picoult, Jodi</td>\n",
       "      <td>1,003,780</td>\n",
       "      <td>Hodder &amp; Stoughton</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Amber Spyglass,The:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,002,314</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Lee, Harper</td>\n",
       "      <td>998,213</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Men are from Mars, Women are from Venus:A Prac...</td>\n",
       "      <td>Gray, John</td>\n",
       "      <td>992,846</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Popular Culture &amp; Media: General Interest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Dear Fatty</td>\n",
       "      <td>French, Dawn</td>\n",
       "      <td>986,753</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Short History of Tractors in Ukrainian,A</td>\n",
       "      <td>Lewycka, Marina</td>\n",
       "      <td>986,115</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Hannibal</td>\n",
       "      <td>Harris, Thomas</td>\n",
       "      <td>970,509</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Lord of the Rings,The</td>\n",
       "      <td>Tolkien, J. R. R.</td>\n",
       "      <td>967,466</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Stupid White Men:...and Other Sorry Excuses fo...</td>\n",
       "      <td>Moore, Michael</td>\n",
       "      <td>963,353</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Current Affairs &amp; Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Interpretation of Murder,The</td>\n",
       "      <td>Rubenfeld, Jed</td>\n",
       "      <td>962,515</td>\n",
       "      <td>Headline</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sharon Osbourne Extreme:My Autobiography</td>\n",
       "      <td>Osbourne, Sharon</td>\n",
       "      <td>959,496</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Alchemist,The:A Fable About Following Your Dream</td>\n",
       "      <td>Coelho, Paulo</td>\n",
       "      <td>956,114</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>At My Mother's Knee ...:and Other Low Joints</td>\n",
       "      <td>O'Grady, Paul</td>\n",
       "      <td>945,640</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Notes from a Small Island</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>931,312</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Return of the Naked Chef,The</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>925,425</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Bridget Jones: The Edge of Reason</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>924,695</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Jamie's Italy</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>906,968</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>National &amp; Regional Cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>I Can Make You Thin</td>\n",
       "      <td>McKenna, Paul</td>\n",
       "      <td>905,086</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Down Under</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>890,847</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Summons,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>869,671</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Small Island</td>\n",
       "      <td>Levy, Andrea</td>\n",
       "      <td>869,659</td>\n",
       "      <td>Headline</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Nigella Express</td>\n",
       "      <td>Lawson, Nigella</td>\n",
       "      <td>862,602</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Brick Lane</td>\n",
       "      <td>Ali, Monica</td>\n",
       "      <td>856,540</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Memory Keeper's Daughter,The</td>\n",
       "      <td>Edwards, Kim</td>\n",
       "      <td>845,858</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Room on the Broom</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>842,535</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>About a Boy</td>\n",
       "      <td>Hornby, Nick</td>\n",
       "      <td>828,215</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>My Booky Wook</td>\n",
       "      <td>Brand, Russell</td>\n",
       "      <td>820,563</td>\n",
       "      <td>Hodder &amp; Stoughton</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>God Delusion,The</td>\n",
       "      <td>Dawkins, Richard</td>\n",
       "      <td>816,907</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>\"Beano\" Annual,The</td>\n",
       "      <td>0</td>\n",
       "      <td>816,585</td>\n",
       "      <td>D.C. Thomson</td>\n",
       "      <td>Children's Annuals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>White Teeth</td>\n",
       "      <td>Smith, Zadie</td>\n",
       "      <td>815,586</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>House at Riverton,The</td>\n",
       "      <td>Morton, Kate</td>\n",
       "      <td>814,370</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Book Thief,The</td>\n",
       "      <td>Zusak, Markus</td>\n",
       "      <td>809,641</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Nights of Rain and Stars</td>\n",
       "      <td>Binchy, Maeve</td>\n",
       "      <td>808,900</td>\n",
       "      <td>Orion</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name  \\\n",
       "0                                   Da Vinci Code,The   \n",
       "1                Harry Potter and the Deathly Hallows   \n",
       "2            Harry Potter and the Philosopher's Stone   \n",
       "3           Harry Potter and the Order of the Phoenix   \n",
       "4                                Fifty Shades of Grey   \n",
       "5                 Harry Potter and the Goblet of Fire   \n",
       "6             Harry Potter and the Chamber of Secrets   \n",
       "7            Harry Potter and the Prisoner of Azkaban   \n",
       "8                                   Angels and Demons   \n",
       "9   Harry Potter and the Half-blood Prince:Childre...   \n",
       "10                                Fifty Shades Darker   \n",
       "11                                           Twilight   \n",
       "12  Girl with the Dragon Tattoo,The:Millennium Tri...   \n",
       "13                                 Fifty Shades Freed   \n",
       "14                                    Lost Symbol,The   \n",
       "15                                           New Moon   \n",
       "16                                    Deception Point   \n",
       "17                                            Eclipse   \n",
       "18                                   Lovely Bones,The   \n",
       "19  Curious Incident of the Dog in the Night-time,The   \n",
       "20                                   Digital Fortress   \n",
       "21               Short History of Nearly Everything,A   \n",
       "22   Girl Who Played with Fire,The:Millennium Trilogy   \n",
       "23                                      Breaking Dawn   \n",
       "24  Very Hungry Caterpillar,The:The Very Hungry Ca...   \n",
       "25                                       Gruffalo,The   \n",
       "26                            Jamie's 30-Minute Meals   \n",
       "27                                    Kite Runner,The   \n",
       "28                                            One Day   \n",
       "29                           Thousand Splendid Suns,A   \n",
       "30  Girl Who Kicked the Hornets' Nest,The:Millenni...   \n",
       "31                           Time Traveler's Wife,The   \n",
       "32                                          Atonement   \n",
       "33                      Bridget Jones's Diary:A Novel   \n",
       "34                    World According to Clarkson,The   \n",
       "35                         Captain Corelli's Mandolin   \n",
       "36                              Sound of Laughter,The   \n",
       "37                                         Life of Pi   \n",
       "38                                     Billy Connolly   \n",
       "39                                  Child Called It,A   \n",
       "40                               Gruffalo's Child,The   \n",
       "41             Angela's Ashes:A Memoir of a Childhood   \n",
       "42                                           Birdsong   \n",
       "43              Northern Lights:His Dark Materials S.   \n",
       "44                                          Labyrinth   \n",
       "45             Harry Potter and the Half-blood Prince   \n",
       "46                                           Help,The   \n",
       "47                                        Man and Boy   \n",
       "48                                Memoirs of a Geisha   \n",
       "49  No.1 Ladies' Detective Agency,The:No.1 Ladies'...   \n",
       "50                                         Island,The   \n",
       "51                                     PS, I Love You   \n",
       "52  You are What You Eat:The Plan That Will Change...   \n",
       "53                             Shadow of the Wind,The   \n",
       "54                       Tales of Beedle the Bard,The   \n",
       "55                                         Broker,The   \n",
       "56  Dr. Atkins' New Diet Revolution:The No-hunger,...   \n",
       "57             Subtle Knife,The:His Dark Materials S.   \n",
       "58  Eats, Shoots and Leaves:The Zero Tolerance App...   \n",
       "59                         Delia's How to Cook:(Bk.1)   \n",
       "60                                           Chocolat   \n",
       "61                     Boy in the Striped Pyjamas,The   \n",
       "62                                 My Sister's Keeper   \n",
       "63           Amber Spyglass,The:His Dark Materials S.   \n",
       "64                              To Kill a Mockingbird   \n",
       "65  Men are from Mars, Women are from Venus:A Prac...   \n",
       "66                                         Dear Fatty   \n",
       "67           Short History of Tractors in Ukrainian,A   \n",
       "68                                           Hannibal   \n",
       "69                              Lord of the Rings,The   \n",
       "70  Stupid White Men:...and Other Sorry Excuses fo...   \n",
       "71                       Interpretation of Murder,The   \n",
       "72           Sharon Osbourne Extreme:My Autobiography   \n",
       "73   Alchemist,The:A Fable About Following Your Dream   \n",
       "74       At My Mother's Knee ...:and Other Low Joints   \n",
       "75                          Notes from a Small Island   \n",
       "76                       Return of the Naked Chef,The   \n",
       "77                  Bridget Jones: The Edge of Reason   \n",
       "78                                      Jamie's Italy   \n",
       "79                                I Can Make You Thin   \n",
       "80                                         Down Under   \n",
       "81                                        Summons,The   \n",
       "82                                       Small Island   \n",
       "83                                    Nigella Express   \n",
       "84                                         Brick Lane   \n",
       "85                       Memory Keeper's Daughter,The   \n",
       "86                                  Room on the Broom   \n",
       "87                                        About a Boy   \n",
       "88                                      My Booky Wook   \n",
       "89                                   God Delusion,The   \n",
       "90                                 \"Beano\" Annual,The   \n",
       "91                                        White Teeth   \n",
       "92                              House at Riverton,The   \n",
       "93                                     Book Thief,The   \n",
       "94                           Nights of Rain and Stars   \n",
       "95                                          Ghost,The   \n",
       "96                     Happy Days with the Naked Chef   \n",
       "97              Hunger Games,The:Hunger Games Trilogy   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...   \n",
       "\n",
       "                Author_name Volumes_sold                       Publisher  \\\n",
       "0                Brown, Dan    5,094,805                      Transworld   \n",
       "1             Rowling, J.K.    4,475,152                      Bloomsbury   \n",
       "2             Rowling, J.K.    4,200,654                      Bloomsbury   \n",
       "3             Rowling, J.K.    4,179,479                      Bloomsbury   \n",
       "4              James, E. L.    3,758,936                    Random House   \n",
       "5             Rowling, J.K.    3,583,215                      Bloomsbury   \n",
       "6             Rowling, J.K.    3,484,047                      Bloomsbury   \n",
       "7             Rowling, J.K.    3,377,906                      Bloomsbury   \n",
       "8                Brown, Dan    3,193,946                      Transworld   \n",
       "9             Rowling, J.K.    2,950,264                      Bloomsbury   \n",
       "10             James, E. L.    2,479,784                    Random House   \n",
       "11         Meyer, Stephenie    2,315,405              Little, Brown Book   \n",
       "12           Larsson, Stieg    2,233,570                         Quercus   \n",
       "13             James, E. L.    2,193,928                    Random House   \n",
       "14               Brown, Dan    2,183,031                      Transworld   \n",
       "15         Meyer, Stephenie    2,152,737              Little, Brown Book   \n",
       "16               Brown, Dan    2,062,145                      Transworld   \n",
       "17         Meyer, Stephenie    2,052,876              Little, Brown Book   \n",
       "18            Sebold, Alice    2,005,598                   Pan Macmillan   \n",
       "19             Haddon, Mark    1,979,552                    Random House   \n",
       "20               Brown, Dan    1,928,900                      Transworld   \n",
       "21             Bryson, Bill    1,852,919                      Transworld   \n",
       "22           Larsson, Stieg    1,814,784                         Quercus   \n",
       "23         Meyer, Stephenie    1,787,118              Little, Brown Book   \n",
       "24              Carle, Eric    1,783,535                         Penguin   \n",
       "25         Donaldson, Julia    1,781,269                   Pan Macmillan   \n",
       "26            Oliver, Jamie    1,743,266                         Penguin   \n",
       "27         Hosseini, Khaled    1,629,119                      Bloomsbury   \n",
       "28          Nicholls, David    1,616,068              Hodder & Stoughton   \n",
       "29         Hosseini, Khaled    1,583,992                      Bloomsbury   \n",
       "30           Larsson, Stieg    1,555,135                         Quercus   \n",
       "31      Niffenegger, Audrey    1,546,886                    Random House   \n",
       "32              McEwan, Ian    1,539,428                    Random House   \n",
       "33          Fielding, Helen    1,508,205                   Pan Macmillan   \n",
       "34         Clarkson, Jeremy    1,489,403                         Penguin   \n",
       "35      Bernieres, Louis de    1,352,318                    Random House   \n",
       "36               Kay, Peter    1,310,207                    Random House   \n",
       "37             Martel, Yann    1,310,176                       Canongate   \n",
       "38       Stephenson, Pamela    1,231,957                   HarperCollins   \n",
       "39             Pelzer, Dave    1,217,712                           Orion   \n",
       "40         Donaldson, Julia    1,208,711                   Pan Macmillan   \n",
       "41           McCourt, Frank    1,204,058                   HarperCollins   \n",
       "42        Faulks, Sebastian    1,184,967                    Random House   \n",
       "43          Pullman, Philip    1,181,503                 Scholastic Ltd.   \n",
       "44              Mosse, Kate    1,181,093                           Orion   \n",
       "45            Rowling, J.K.    1,153,181                      Bloomsbury   \n",
       "46        Stockett, Kathryn    1,132,336                         Penguin   \n",
       "47            Parsons, Tony    1,130,802                   HarperCollins   \n",
       "48           Golden, Arthur    1,126,337                    Random House   \n",
       "49  McCall Smith, Alexander    1,115,549              Little, Brown Book   \n",
       "50         Hislop, Victoria    1,108,328                        Headline   \n",
       "51           Ahern, Cecelia    1,107,379                   HarperCollins   \n",
       "52         McKeith, Gillian    1,104,403                         Penguin   \n",
       "53       Zafon, Carlos Ruiz    1,092,349                           Orion   \n",
       "54            Rowling, J.K.    1,090,847                      Bloomsbury   \n",
       "55            Grisham, John    1,087,262                    Random House   \n",
       "56        Atkins, Robert C.    1,054,196                    Random House   \n",
       "57          Pullman, Philip    1,037,160                 Scholastic Ltd.   \n",
       "58             Truss, Lynne    1,023,688             Profile Books Group   \n",
       "59             Smith, Delia    1,015,956                    Random House   \n",
       "60           Harris, Joanne    1,009,873                      Transworld   \n",
       "61              Boyne, John    1,004,414  Random House Childrens Books G   \n",
       "62            Picoult, Jodi    1,003,780              Hodder & Stoughton   \n",
       "63          Pullman, Philip    1,002,314                 Scholastic Ltd.   \n",
       "64              Lee, Harper      998,213                    Random House   \n",
       "65               Gray, John      992,846                   HarperCollins   \n",
       "66             French, Dawn      986,753                    Random House   \n",
       "67          Lewycka, Marina      986,115                         Penguin   \n",
       "68           Harris, Thomas      970,509                    Random House   \n",
       "69        Tolkien, J. R. R.      967,466                   HarperCollins   \n",
       "70           Moore, Michael      963,353                         Penguin   \n",
       "71           Rubenfeld, Jed      962,515                        Headline   \n",
       "72         Osbourne, Sharon      959,496              Little, Brown Book   \n",
       "73            Coelho, Paulo      956,114                   HarperCollins   \n",
       "74            O'Grady, Paul      945,640                      Transworld   \n",
       "75             Bryson, Bill      931,312                      Transworld   \n",
       "76            Oliver, Jamie      925,425                         Penguin   \n",
       "77          Fielding, Helen      924,695                   Pan Macmillan   \n",
       "78            Oliver, Jamie      906,968                         Penguin   \n",
       "79            McKenna, Paul      905,086                      Transworld   \n",
       "80             Bryson, Bill      890,847                      Transworld   \n",
       "81            Grisham, John      869,671                    Random House   \n",
       "82             Levy, Andrea      869,659                        Headline   \n",
       "83          Lawson, Nigella      862,602                    Random House   \n",
       "84              Ali, Monica      856,540                      Transworld   \n",
       "85             Edwards, Kim      845,858                         Penguin   \n",
       "86         Donaldson, Julia      842,535                   Pan Macmillan   \n",
       "87             Hornby, Nick      828,215                         Penguin   \n",
       "88           Brand, Russell      820,563              Hodder & Stoughton   \n",
       "89         Dawkins, Richard      816,907                      Transworld   \n",
       "90                        0      816,585                    D.C. Thomson   \n",
       "91             Smith, Zadie      815,586                         Penguin   \n",
       "92             Morton, Kate      814,370                   Pan Macmillan   \n",
       "93            Zusak, Markus      809,641                      Transworld   \n",
       "94            Binchy, Maeve      808,900                           Orion   \n",
       "95           Harris, Robert      807,311                    Random House   \n",
       "96            Oliver, Jamie      794,201                         Penguin   \n",
       "97         Collins, Suzanne      792,187                 Scholastic Ltd.   \n",
       "98             Pelzer, Dave      791,507                           Orion   \n",
       "99            Oliver, Jamie      791,095                         Penguin   \n",
       "\n",
       "                                        Genre  \n",
       "0                 Crime, Thriller & Adventure  \n",
       "1                          Children's Fiction  \n",
       "2                          Children's Fiction  \n",
       "3                          Children's Fiction  \n",
       "4                             Romance & Sagas  \n",
       "5                          Children's Fiction  \n",
       "6                          Children's Fiction  \n",
       "7                          Children's Fiction  \n",
       "8                 Crime, Thriller & Adventure  \n",
       "9                          Children's Fiction  \n",
       "10                            Romance & Sagas  \n",
       "11                        Young Adult Fiction  \n",
       "12                Crime, Thriller & Adventure  \n",
       "13                            Romance & Sagas  \n",
       "14                Crime, Thriller & Adventure  \n",
       "15                        Young Adult Fiction  \n",
       "16                Crime, Thriller & Adventure  \n",
       "17                        Young Adult Fiction  \n",
       "18                 General & Literary Fiction  \n",
       "19                 General & Literary Fiction  \n",
       "20                Crime, Thriller & Adventure  \n",
       "21                            Popular Science  \n",
       "22                Crime, Thriller & Adventure  \n",
       "23                        Young Adult Fiction  \n",
       "24                              Picture Books  \n",
       "25                              Picture Books  \n",
       "26                      Food & Drink: General  \n",
       "27                 General & Literary Fiction  \n",
       "28                 General & Literary Fiction  \n",
       "29                 General & Literary Fiction  \n",
       "30                Crime, Thriller & Adventure  \n",
       "31                 General & Literary Fiction  \n",
       "32                 General & Literary Fiction  \n",
       "33                 General & Literary Fiction  \n",
       "34              Humour: Collections & General  \n",
       "35                 General & Literary Fiction  \n",
       "36                     Autobiography: General  \n",
       "37                 General & Literary Fiction  \n",
       "38                        Biography: The Arts  \n",
       "39                     Autobiography: General  \n",
       "40                              Picture Books  \n",
       "41                     Autobiography: General  \n",
       "42                 General & Literary Fiction  \n",
       "43                        Young Adult Fiction  \n",
       "44                 General & Literary Fiction  \n",
       "45                  Science Fiction & Fantasy  \n",
       "46                 General & Literary Fiction  \n",
       "47                 General & Literary Fiction  \n",
       "48                 General & Literary Fiction  \n",
       "49                Crime, Thriller & Adventure  \n",
       "50                 General & Literary Fiction  \n",
       "51                 General & Literary Fiction  \n",
       "52                             Fitness & Diet  \n",
       "53                 General & Literary Fiction  \n",
       "54                         Children's Fiction  \n",
       "55                Crime, Thriller & Adventure  \n",
       "56                             Fitness & Diet  \n",
       "57                        Young Adult Fiction  \n",
       "58                     Usage & Writing Guides  \n",
       "59                      Food & Drink: General  \n",
       "60                 General & Literary Fiction  \n",
       "61                        Young Adult Fiction  \n",
       "62                 General & Literary Fiction  \n",
       "63                        Young Adult Fiction  \n",
       "64                 General & Literary Fiction  \n",
       "65  Popular Culture & Media: General Interest  \n",
       "66                    Autobiography: The Arts  \n",
       "67                 General & Literary Fiction  \n",
       "68                Crime, Thriller & Adventure  \n",
       "69                  Science Fiction & Fantasy  \n",
       "70                   Current Affairs & Issues  \n",
       "71                Crime, Thriller & Adventure  \n",
       "72                    Autobiography: The Arts  \n",
       "73                 General & Literary Fiction  \n",
       "74                    Autobiography: The Arts  \n",
       "75                             Travel Writing  \n",
       "76                      Food & Drink: General  \n",
       "77                 General & Literary Fiction  \n",
       "78                National & Regional Cuisine  \n",
       "79                             Fitness & Diet  \n",
       "80                             Travel Writing  \n",
       "81                Crime, Thriller & Adventure  \n",
       "82                 General & Literary Fiction  \n",
       "83                      Food & Drink: General  \n",
       "84                 General & Literary Fiction  \n",
       "85                 General & Literary Fiction  \n",
       "86                              Picture Books  \n",
       "87                 General & Literary Fiction  \n",
       "88                    Autobiography: The Arts  \n",
       "89                            Popular Science  \n",
       "90                         Children's Annuals  \n",
       "91                 General & Literary Fiction  \n",
       "92                 General & Literary Fiction  \n",
       "93                 General & Literary Fiction  \n",
       "94                 General & Literary Fiction  \n",
       "95                 General & Literary Fiction  \n",
       "96                      Food & Drink: General  \n",
       "97                        Young Adult Fiction  \n",
       "98                         Biography: General  \n",
       "99                      Food & Drink: General  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "Highest_selling_novels()#calling the Function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostwatched_tv_series():\n",
    "    \"\"\"The Function which searches and returns top selling novels from theguardian.com\"\"\"\n",
    "\n",
    "    template = 'https://www.imdb.com/list/ls095964455/' #URL template for accessing the website.\n",
    "    driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    #Creating the list Name and scraping the name of TV shows.\n",
    "    Name = [i.text for i in driver.find_elements_by_xpath(\"//h3 [@class ='lister-item-header']/a\")]\n",
    "    \n",
    "    #Creating the list Year_span and scraping the Year_span of TV shows.\n",
    "    Year_span = [i.text for i in driver.find_elements_by_xpath(\"//h3 [@class ='lister-item-header']/span[@class = 'lister-item-year text-muted unbold']\")]\n",
    "    \n",
    "    #Creating the list Genre and scraping the Genre of TV shows.\n",
    "    Genre = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='text-muted text-small']/span[@class = 'genre']\")]\n",
    "    \n",
    "    #Creating the list Run_time and scraping the Run_time of TV shows.\n",
    "    Run_time = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='text-muted text-small']/span[@class = 'runtime']\")]\n",
    "    \n",
    "    #Creating the list Ratings and scraping the Ratings of TV shows.\n",
    "    Ratings = [i.text for i in driver.find_elements_by_xpath(\"//div [@class ='ipl-rating-star small']/span[@class = 'ipl-rating-star__rating']\")]\n",
    "    \n",
    "    #Creating the list Votes and scraping the Votes of TV shows.\n",
    "    Votes = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='text-muted text-small']/span[@name = 'nv']\")]\n",
    "    \n",
    "    driver.quit()#exiting the driver post scraping the information\n",
    "    \n",
    "    #Creating a Dataframe with all collected details.\n",
    "    table = pd.DataFrame({\"Name\" : Name,\n",
    "                          \"Year_span\" : Year_span,\n",
    "                          \"Genre\" : Genre,\n",
    "                          \"Run_time\" : Run_time,\n",
    "                          \"Ratings\": Ratings,\n",
    "                          \"Votes\" : Votes})\n",
    "    \n",
    "    return table #Returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,835,393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>874,161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>879,319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>225,709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orange Is the New Black</td>\n",
       "      <td>(2013–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>59 min</td>\n",
       "      <td>8</td>\n",
       "      <td>283,523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riverdale</td>\n",
       "      <td>(2017– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.8</td>\n",
       "      <td>125,076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>263,661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Flash</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>316,948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arrow</td>\n",
       "      <td>(2012–2020)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>413,424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Money Heist</td>\n",
       "      <td>(2017–2021)</td>\n",
       "      <td>Action, Crime, Mystery</td>\n",
       "      <td>70 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>337,414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>(2007–2019)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>740,421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Mirror</td>\n",
       "      <td>(2011– )</td>\n",
       "      <td>Drama, Sci-Fi, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>466,004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sherlock</td>\n",
       "      <td>(2010–2017)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>88 min</td>\n",
       "      <td>9.1</td>\n",
       "      <td>834,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vikings</td>\n",
       "      <td>(2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>455,512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pretty Little Liars</td>\n",
       "      <td>(2010–2017)</td>\n",
       "      <td>Drama, Mystery, Romance</td>\n",
       "      <td>44 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>155,225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Vampire Diaries</td>\n",
       "      <td>(2009–2017)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>292,045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>American Horror Story</td>\n",
       "      <td>(2011– )</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8</td>\n",
       "      <td>283,971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>(2008–2013)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1,539,328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lucifer</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Crime, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>258,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Supernatural</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>401,760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Prison Break</td>\n",
       "      <td>(2005–2017)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>490,116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How to Get Away with Murder</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>135,168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>132,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>373,713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Once Upon a Time</td>\n",
       "      <td>(2011–2018)</td>\n",
       "      <td>Adventure, Fantasy, Romance</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>211,935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Narcos</td>\n",
       "      <td>(2015–2017)</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>373,001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Daredevil</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>54 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>372,850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Friends</td>\n",
       "      <td>(1994–2004)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>872,451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How I Met Your Mother</td>\n",
       "      <td>(2005–2014)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>621,130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Suits</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>372,686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mr. Robot</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>343,913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Originals</td>\n",
       "      <td>(2013–2018)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>121,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Supergirl</td>\n",
       "      <td>(2015–2021)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>6.2</td>\n",
       "      <td>114,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gossip Girl</td>\n",
       "      <td>(2007–2012)</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>158,527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sense8</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>143,418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gotham</td>\n",
       "      <td>(2014–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>215,562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Westworld</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>62 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>442,084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jessica Jones</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>56 min</td>\n",
       "      <td>7.9</td>\n",
       "      <td>197,094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Modern Family</td>\n",
       "      <td>(2009–2020)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>374,090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Rick and Morty</td>\n",
       "      <td>(2013– )</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>23 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>404,718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Shadowhunters</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>6.6</td>\n",
       "      <td>55,779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The End of the F***ing World</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Crime</td>\n",
       "      <td>25 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>156,104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>House of Cards</td>\n",
       "      <td>(2013–2018)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>475,022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dark</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>309,268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Elite</td>\n",
       "      <td>(2018– )</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>57,930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sex Education</td>\n",
       "      <td>(2019– )</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>174,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Shameless</td>\n",
       "      <td>(2011–2021)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>46 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>212,104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>New Girl</td>\n",
       "      <td>(2011–2018)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>199,286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Agents of S.H.I.E.L.D.</td>\n",
       "      <td>(2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>204,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>You</td>\n",
       "      <td>(2018– )</td>\n",
       "      <td>Crime, Drama, Romance</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>155,754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Dexter</td>\n",
       "      <td>(2006–2021)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>53 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>661,238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Fear the Walking Dead</td>\n",
       "      <td>(2015– )</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "      <td>44 min</td>\n",
       "      <td>6.9</td>\n",
       "      <td>117,302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Family Guy</td>\n",
       "      <td>(1999–2022)</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>311,122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>The Blacklist</td>\n",
       "      <td>(2013– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8</td>\n",
       "      <td>210,844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Lost</td>\n",
       "      <td>(2004–2010)</td>\n",
       "      <td>Adventure, Drama, Fantasy</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>509,685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>(2013– )</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>386,735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>House</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Drama, Mystery</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>424,317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Quantico</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>6.7</td>\n",
       "      <td>57,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Orphan Black</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Action, Drama, Sci-Fi</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>103,905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Homeland</td>\n",
       "      <td>(2011–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>321,245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Blindspot</td>\n",
       "      <td>(2015–2020)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67,978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>DC's Legends of Tomorrow</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>6.8</td>\n",
       "      <td>95,166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>The Handmaid's Tale</td>\n",
       "      <td>(2017– )</td>\n",
       "      <td>Drama, Sci-Fi, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>191,958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Chilling Adventures of Sabrina</td>\n",
       "      <td>(2018–2020)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>81,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>The Good Doctor</td>\n",
       "      <td>(2017– )</td>\n",
       "      <td>Drama</td>\n",
       "      <td>41 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>68,554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Jane the Virgin</td>\n",
       "      <td>(2014–2019)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>41,207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Glee</td>\n",
       "      <td>(2009–2015)</td>\n",
       "      <td>Comedy, Drama, Music</td>\n",
       "      <td>44 min</td>\n",
       "      <td>6.7</td>\n",
       "      <td>139,333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>South Park</td>\n",
       "      <td>(1997– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>338,457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Brooklyn Nine-Nine</td>\n",
       "      <td>(2013–2022)</td>\n",
       "      <td>Comedy, Crime</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>245,512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Under the Dome</td>\n",
       "      <td>(2013–2015)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>6.6</td>\n",
       "      <td>102,393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>The Umbrella Academy</td>\n",
       "      <td>(2019– )</td>\n",
       "      <td>Action, Adventure, Comedy</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8</td>\n",
       "      <td>173,337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014–2019)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>512,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>94,109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>119,184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>(2015– )</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>46 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>344,466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Bates Motel</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>99,765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>The Punisher</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>53 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>193,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Atypical</td>\n",
       "      <td>(2017–2021)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>30 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>66,365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Dynasty</td>\n",
       "      <td>(2017– )</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.3</td>\n",
       "      <td>16,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>This Is Us</td>\n",
       "      <td>(2016–2022)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>115,454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>The Good Place</td>\n",
       "      <td>(2016–2020)</td>\n",
       "      <td>Comedy, Drama, Fantasy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>125,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Iron Fist</td>\n",
       "      <td>(2017–2018)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>55 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>118,098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>The Rain</td>\n",
       "      <td>(2018–2020)</td>\n",
       "      <td>Drama, Sci-Fi, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.3</td>\n",
       "      <td>32,583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Mindhunter</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>233,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Revenge</td>\n",
       "      <td>(2011–2015)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>114,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Luke Cage</td>\n",
       "      <td>(2016–2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>7.3</td>\n",
       "      <td>119,541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Scandal</td>\n",
       "      <td>(2012–2018)</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>68,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>The Defenders</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.3</td>\n",
       "      <td>93,919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Big Little Lies</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>166,664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Insatiable</td>\n",
       "      <td>(2018–2019)</td>\n",
       "      <td>Comedy, Drama, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>23,880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The Mentalist</td>\n",
       "      <td>(2008–2015)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>169,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The Crown</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Biography, Drama, History</td>\n",
       "      <td>58 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>167,935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Chernobyl</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>Drama, History, Thriller</td>\n",
       "      <td>330 min</td>\n",
       "      <td>9.4</td>\n",
       "      <td>589,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>iZombie</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>169,584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35,120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>193,351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                         Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)      Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )        Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)       Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)      Drama, Mystery, Thriller   \n",
       "4                          The 100     (2014– )        Drama, Mystery, Sci-Fi   \n",
       "5          Orange Is the New Black  (2013–2019)          Comedy, Crime, Drama   \n",
       "6                        Riverdale     (2017– )         Crime, Drama, Mystery   \n",
       "7                   Grey's Anatomy     (2005– )                Drama, Romance   \n",
       "8                        The Flash     (2014– )      Action, Adventure, Drama   \n",
       "9                            Arrow  (2012–2020)      Action, Adventure, Crime   \n",
       "10                     Money Heist  (2017–2021)        Action, Crime, Mystery   \n",
       "11             The Big Bang Theory  (2007–2019)               Comedy, Romance   \n",
       "12                    Black Mirror     (2011– )       Drama, Sci-Fi, Thriller   \n",
       "13                        Sherlock  (2010–2017)         Crime, Drama, Mystery   \n",
       "14                         Vikings  (2013–2020)      Action, Adventure, Drama   \n",
       "15             Pretty Little Liars  (2010–2017)       Drama, Mystery, Romance   \n",
       "16             The Vampire Diaries  (2009–2017)        Drama, Fantasy, Horror   \n",
       "17           American Horror Story     (2011– )       Drama, Horror, Thriller   \n",
       "18                    Breaking Bad  (2008–2013)        Crime, Drama, Thriller   \n",
       "19                         Lucifer     (2016– )         Crime, Drama, Fantasy   \n",
       "20                    Supernatural  (2005–2020)        Drama, Fantasy, Horror   \n",
       "21                    Prison Break  (2005–2017)          Action, Crime, Drama   \n",
       "22     How to Get Away with Murder  (2014–2020)         Crime, Drama, Mystery   \n",
       "23                       Teen Wolf  (2011–2017)        Action, Drama, Fantasy   \n",
       "24                    The Simpsons     (1989– )             Animation, Comedy   \n",
       "25                Once Upon a Time  (2011–2018)   Adventure, Fantasy, Romance   \n",
       "26                          Narcos  (2015–2017)       Biography, Crime, Drama   \n",
       "27                       Daredevil  (2015–2018)          Action, Crime, Drama   \n",
       "28                         Friends  (1994–2004)               Comedy, Romance   \n",
       "29           How I Met Your Mother  (2005–2014)               Comedy, Romance   \n",
       "30                           Suits  (2011–2019)                 Comedy, Drama   \n",
       "31                       Mr. Robot  (2015–2019)        Crime, Drama, Thriller   \n",
       "32                   The Originals  (2013–2018)        Drama, Fantasy, Horror   \n",
       "33                       Supergirl  (2015–2021)      Action, Adventure, Drama   \n",
       "34                     Gossip Girl  (2007–2012)                Drama, Romance   \n",
       "35                          Sense8  (2015–2018)        Drama, Mystery, Sci-Fi   \n",
       "36                          Gotham  (2014–2019)          Action, Crime, Drama   \n",
       "37                       Westworld     (2016– )        Drama, Mystery, Sci-Fi   \n",
       "38                   Jessica Jones  (2015–2019)          Action, Crime, Drama   \n",
       "39                   Modern Family  (2009–2020)        Comedy, Drama, Romance   \n",
       "40                  Rick and Morty     (2013– )  Animation, Adventure, Comedy   \n",
       "41                   Shadowhunters  (2016–2019)        Action, Drama, Fantasy   \n",
       "42    The End of the F***ing World  (2017–2019)      Adventure, Comedy, Crime   \n",
       "43                  House of Cards  (2013–2018)                         Drama   \n",
       "44                            Dark  (2017–2020)         Crime, Drama, Mystery   \n",
       "45                           Elite     (2018– )        Crime, Drama, Thriller   \n",
       "46                   Sex Education     (2019– )                 Comedy, Drama   \n",
       "47                       Shameless  (2011–2021)                 Comedy, Drama   \n",
       "48                        New Girl  (2011–2018)                        Comedy   \n",
       "49          Agents of S.H.I.E.L.D.  (2013–2020)      Action, Adventure, Drama   \n",
       "50                             You     (2018– )         Crime, Drama, Romance   \n",
       "51                          Dexter  (2006–2021)         Crime, Drama, Mystery   \n",
       "52           Fear the Walking Dead     (2015– )         Drama, Horror, Sci-Fi   \n",
       "53                      Family Guy  (1999–2022)             Animation, Comedy   \n",
       "54                   The Blacklist     (2013– )         Crime, Drama, Mystery   \n",
       "55                            Lost  (2004–2010)     Adventure, Drama, Fantasy   \n",
       "56                  Peaky Blinders     (2013– )                  Crime, Drama   \n",
       "57                           House  (2004–2012)                Drama, Mystery   \n",
       "58                        Quantico  (2015–2018)         Crime, Drama, Mystery   \n",
       "59                    Orphan Black  (2013–2017)         Action, Drama, Sci-Fi   \n",
       "60                        Homeland  (2011–2020)         Crime, Drama, Mystery   \n",
       "61                       Blindspot  (2015–2020)          Action, Crime, Drama   \n",
       "62        DC's Legends of Tomorrow     (2016– )      Action, Adventure, Drama   \n",
       "63             The Handmaid's Tale     (2017– )       Drama, Sci-Fi, Thriller   \n",
       "64  Chilling Adventures of Sabrina  (2018–2020)        Drama, Fantasy, Horror   \n",
       "65                 The Good Doctor     (2017– )                         Drama   \n",
       "66                 Jane the Virgin  (2014–2019)                        Comedy   \n",
       "67                            Glee  (2009–2015)          Comedy, Drama, Music   \n",
       "68                      South Park     (1997– )             Animation, Comedy   \n",
       "69              Brooklyn Nine-Nine  (2013–2022)                 Comedy, Crime   \n",
       "70                  Under the Dome  (2013–2015)        Drama, Mystery, Sci-Fi   \n",
       "71            The Umbrella Academy     (2019– )     Action, Adventure, Comedy   \n",
       "72                  True Detective  (2014–2019)         Crime, Drama, Mystery   \n",
       "73                          The OA  (2016–2019)       Drama, Fantasy, Mystery   \n",
       "74            Desperate Housewives  (2004–2012)        Comedy, Drama, Mystery   \n",
       "75                Better Call Saul     (2015– )                  Crime, Drama   \n",
       "76                     Bates Motel  (2013–2017)        Drama, Horror, Mystery   \n",
       "77                    The Punisher  (2017–2019)          Action, Crime, Drama   \n",
       "78                        Atypical  (2017–2021)                 Comedy, Drama   \n",
       "79                         Dynasty     (2017– )                         Drama   \n",
       "80                      This Is Us  (2016–2022)        Comedy, Drama, Romance   \n",
       "81                  The Good Place  (2016–2020)        Comedy, Drama, Fantasy   \n",
       "82                       Iron Fist  (2017–2018)      Action, Adventure, Crime   \n",
       "83                        The Rain  (2018–2020)       Drama, Sci-Fi, Thriller   \n",
       "84                      Mindhunter  (2017–2019)        Crime, Drama, Thriller   \n",
       "85                         Revenge  (2011–2015)      Drama, Mystery, Thriller   \n",
       "86                       Luke Cage  (2016–2018)          Action, Crime, Drama   \n",
       "87                         Scandal  (2012–2018)               Drama, Thriller   \n",
       "88                   The Defenders       (2017)      Action, Adventure, Crime   \n",
       "89                 Big Little Lies  (2017–2019)         Crime, Drama, Mystery   \n",
       "90                      Insatiable  (2018–2019)       Comedy, Drama, Thriller   \n",
       "91                   The Mentalist  (2008–2015)         Crime, Drama, Mystery   \n",
       "92                       The Crown     (2016– )     Biography, Drama, History   \n",
       "93                       Chernobyl       (2019)      Drama, History, Thriller   \n",
       "94                         iZombie  (2015–2019)          Comedy, Crime, Drama   \n",
       "95                           Reign  (2013–2017)                Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)      Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)         Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)          Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)        Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  1,835,393  \n",
       "1    51 min     8.7    874,161  \n",
       "2    44 min     8.2    879,319  \n",
       "3    60 min     7.6    264,212  \n",
       "4    43 min     7.6    225,709  \n",
       "5    59 min       8    283,523  \n",
       "6    45 min     6.8    125,076  \n",
       "7    41 min     7.5    263,661  \n",
       "8    43 min     7.6    316,948  \n",
       "9    42 min     7.5    413,424  \n",
       "10   70 min     8.3    337,414  \n",
       "11   22 min     8.1    740,421  \n",
       "12   60 min     8.8    466,004  \n",
       "13   88 min     9.1    834,669  \n",
       "14   44 min     8.5    455,512  \n",
       "15   44 min     7.4    155,225  \n",
       "16   43 min     7.7    292,045  \n",
       "17   60 min       8    283,971  \n",
       "18   49 min     9.4  1,539,328  \n",
       "19   42 min     8.1    258,797  \n",
       "20   44 min     8.4    401,760  \n",
       "21   44 min     8.3    490,116  \n",
       "22   43 min     8.1    135,168  \n",
       "23   41 min     7.6    132,021  \n",
       "24   22 min     8.6    373,713  \n",
       "25   60 min     7.7    211,935  \n",
       "26   49 min     8.8    373,001  \n",
       "27   54 min     8.6    372,850  \n",
       "28   22 min     8.9    872,451  \n",
       "29   22 min     8.3    621,130  \n",
       "30   44 min     8.4    372,686  \n",
       "31   49 min     8.5    343,913  \n",
       "32   45 min     8.2    121,865  \n",
       "33   43 min     6.2    114,749  \n",
       "34   42 min     7.4    158,527  \n",
       "35   60 min     8.3    143,418  \n",
       "36   42 min     7.8    215,562  \n",
       "37   62 min     8.6    442,084  \n",
       "38   56 min     7.9    197,094  \n",
       "39   22 min     8.4    374,090  \n",
       "40   23 min     9.2    404,718  \n",
       "41   42 min     6.6     55,779  \n",
       "42   25 min     8.1    156,104  \n",
       "43   51 min     8.7    475,022  \n",
       "44   60 min     8.8    309,268  \n",
       "45   60 min     7.5     57,930  \n",
       "46   45 min     8.3    174,475  \n",
       "47   46 min     8.5    212,104  \n",
       "48   22 min     7.7    199,286  \n",
       "49   45 min     7.5    204,284  \n",
       "50   45 min     7.7    155,754  \n",
       "51   53 min     8.6    661,238  \n",
       "52   44 min     6.9    117,302  \n",
       "53   22 min     8.1    311,122  \n",
       "54   43 min       8    210,844  \n",
       "55   44 min     8.3    509,685  \n",
       "56   60 min     8.8    386,735  \n",
       "57   44 min     8.7    424,317  \n",
       "58   42 min     6.7     57,992  \n",
       "59   44 min     8.3    103,905  \n",
       "60   55 min     8.3    321,245  \n",
       "61   42 min     7.4     67,978  \n",
       "62   42 min     6.8     95,166  \n",
       "63   60 min     8.4    191,958  \n",
       "64   60 min     7.5     81,899  \n",
       "65   41 min     8.1     68,554  \n",
       "66   60 min     7.8     41,207  \n",
       "67   44 min     6.7    139,333  \n",
       "68   22 min     8.7    338,457  \n",
       "69   22 min     8.4    245,512  \n",
       "70   43 min     6.6    102,393  \n",
       "71   60 min       8    173,337  \n",
       "72   55 min     8.9    512,923  \n",
       "73   60 min     7.8     94,109  \n",
       "74   45 min     7.5    119,184  \n",
       "75   46 min     8.8    344,466  \n",
       "76   45 min     8.1     99,765  \n",
       "77   53 min     8.5    193,013  \n",
       "78   30 min     8.3     66,365  \n",
       "79   42 min     7.3     16,400  \n",
       "80   45 min     8.7    115,454  \n",
       "81   22 min     8.2    125,759  \n",
       "82   55 min     6.5    118,098  \n",
       "83   45 min     6.3     32,583  \n",
       "84   60 min     8.6    233,119  \n",
       "85   44 min     7.8    114,469  \n",
       "86   55 min     7.3    119,541  \n",
       "87   43 min     7.7     68,465  \n",
       "88   50 min     7.3     93,919  \n",
       "89   60 min     8.5    166,664  \n",
       "90   45 min     6.5     23,880  \n",
       "91   43 min     8.1    169,475  \n",
       "92   58 min     8.6    167,935  \n",
       "93  330 min     9.4    589,235  \n",
       "94   42 min     7.8     61,902  \n",
       "95   42 min     7.5     44,790  \n",
       "96   50 min     7.8     55,397  \n",
       "97   42 min     8.1    169,584  \n",
       "98   45 min     7.1     35,120  \n",
       "99  572 min     8.6    193,351  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "mostwatched_tv_series() #calling the Function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCI_Repository():\n",
    "    \"\"\"The Function that Search all the ML Repository details and return them in DataFrame\"\"\"\n",
    "\n",
    "    template = 'https://archive.ics.uci.edu/' #URL template for accessing the website.\n",
    "    driver = webdriver.Chrome(\"G:\\DataTrained n FlipRobo_Pojects\\chromedriver.exe\") #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    time.sleep(3)#making the function to wait for 3sec\n",
    "    \n",
    "    #finding view all repository and clicking the same.\n",
    "    ml_repository = driver.find_element_by_xpath(\"//span [@class ='normal']/b/a\")\n",
    "    ml_repository.click()\n",
    "    \n",
    "    #creating a dummy list 'details' and scraping Dataset_name, Data_type, Task, Attribute_type, Noof_instances, Noof_attribute, Year.\n",
    "    details = [i.text for i in driver.find_elements_by_xpath(\"//table [@border ='1']/tbody/tr/td\")]\n",
    "    del details[:7] #Removing the unwanted details.\n",
    "    \n",
    "    driver.close() #Closing the Driver post scraping the details.\n",
    "    \n",
    "    Dataset_name = [] #creating list Dataset_name to collect Dataset_name. \n",
    "    Data_type = [] #creating list Data_type to collect Data_type. \n",
    "    Task = [] #creating list Task to collect Task. \n",
    "    Attribute_type = [] #creating list Attribute_type to collect Attribute_type. \n",
    "    Noof_instances = [] #creating list Noof_instances to collect Noof_instances. \n",
    "    Noof_attribute = [] #creating list Noof_attribute to collect Noof_attribute. \n",
    "    Year = [] #creating list Year to collect Year. \n",
    "\n",
    "    z= 0\n",
    "    while z < len(details): #Splitting the Dummy variable and storing it in a appropriate list.\n",
    "        Dataset_name.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Data_type.append(details[z])\n",
    "        z +=1\n",
    "    \n",
    "        Task.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Attribute_type.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Noof_instances.append(details[z])\n",
    "        z +=1\n",
    "    \n",
    "        Noof_attribute.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Year.append(details[z])\n",
    "        z +=1\n",
    "        \n",
    "        \n",
    "    #Creating DataFrame with collected Details    \n",
    "    table = pd.DataFrame({\"Dataset_name\" : Dataset_name,\n",
    "                          \"Data_type\" : Data_type,\n",
    "                          \"Task\" : Task,\n",
    "                          \"Attribute_type\" : Attribute_type,\n",
    "                          \"Noof_instances\" : Noof_instances,\n",
    "                          \"Noof_attribute\" : Noof_attribute,\n",
    "                          \"Year\" : Year})\n",
    "        \n",
    "    table = table.replace(' ', '-')\n",
    "        \n",
    "    return table #returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>Noof_instances</th>\n",
       "      <th>Noof_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial Characters</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>6000</td>\n",
       "      <td>7</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Audiology (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>-</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Audiology (Standardized)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>69</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>398</td>\n",
       "      <td>8</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>205</td>\n",
       "      <td>26</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Badges</td>\n",
       "      <td>Univariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balance Scale</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>625</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Balloons</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>286</td>\n",
       "      <td>9</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>699</td>\n",
       "      <td>10</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Breast Cancer Wisconsin (Prognostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>198</td>\n",
       "      <td>34</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>32</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pittsburgh Bridges</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>108</td>\n",
       "      <td>13</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Dataset_name          Data_type  \\\n",
       "0                                  Abalone      Multivariate    \n",
       "1                                    Adult      Multivariate    \n",
       "2                                Annealing      Multivariate    \n",
       "3             Anonymous Microsoft Web Data                  -   \n",
       "4                               Arrhythmia      Multivariate    \n",
       "5                    Artificial Characters      Multivariate    \n",
       "6                     Audiology (Original)      Multivariate    \n",
       "7                 Audiology (Standardized)      Multivariate    \n",
       "8                                 Auto MPG      Multivariate    \n",
       "9                               Automobile      Multivariate    \n",
       "10                                  Badges  Univariate, Text    \n",
       "11                           Balance Scale      Multivariate    \n",
       "12                                Balloons      Multivariate    \n",
       "13                           Breast Cancer      Multivariate    \n",
       "14      Breast Cancer Wisconsin (Original)      Multivariate    \n",
       "15    Breast Cancer Wisconsin (Prognostic)      Multivariate    \n",
       "16    Breast Cancer Wisconsin (Diagnostic)      Multivariate    \n",
       "17                      Pittsburgh Bridges      Multivariate    \n",
       "18                          Car Evaluation      Multivariate    \n",
       "19                           Census Income      Multivariate    \n",
       "\n",
       "                           Task               Attribute_type Noof_instances  \\\n",
       "0               Classification   Categorical, Integer, Real           4177    \n",
       "1               Classification         Categorical, Integer          48842    \n",
       "2               Classification   Categorical, Integer, Real            798    \n",
       "3          Recommender-Systems                  Categorical          37711    \n",
       "4               Classification   Categorical, Integer, Real            452    \n",
       "5               Classification   Categorical, Integer, Real           6000    \n",
       "6               Classification                  Categorical            226    \n",
       "7               Classification                  Categorical            226    \n",
       "8                   Regression            Categorical, Real            398    \n",
       "9                   Regression   Categorical, Integer, Real            205    \n",
       "10              Classification                             -           294    \n",
       "11              Classification                  Categorical            625    \n",
       "12              Classification                  Categorical             16    \n",
       "13              Classification                  Categorical            286    \n",
       "14              Classification                      Integer            699    \n",
       "15  Classification, Regression                         Real            198    \n",
       "16              Classification                         Real            569    \n",
       "17              Classification         Categorical, Integer            108    \n",
       "18              Classification                  Categorical           1728    \n",
       "19              Classification         Categorical, Integer          48842    \n",
       "\n",
       "   Noof_attribute   Year  \n",
       "0              8   1995   \n",
       "1             14   1996   \n",
       "2             38       -  \n",
       "3            294   1998   \n",
       "4            279   1998   \n",
       "5              7   1992   \n",
       "6               -  1987   \n",
       "7             69   1992   \n",
       "8              8   1993   \n",
       "9             26   1987   \n",
       "10             1   1994   \n",
       "11             4   1994   \n",
       "12             4       -  \n",
       "13             9   1988   \n",
       "14            10   1992   \n",
       "15            34   1995   \n",
       "16            32   1995   \n",
       "17            13   1990   \n",
       "18             6   1997   \n",
       "19            14   1996   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI_Repository = UCI_Repository() #Calling the function and storing it in a variable.\n",
    "UCI_Repository.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
